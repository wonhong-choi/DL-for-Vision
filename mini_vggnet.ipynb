{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7268749691082327432\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2239889408\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11381055852368422095\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers, optimizers\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  (45000, 32, 32, 3)\n",
      "X_valid :  (5000, 32, 32, 3)\n",
      "X_test :  (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_teset = X_test.astype('float32')\n",
    "\n",
    "(X_train, X_valid) = X_train[5000:], X_train[:5000]\n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "print('X_train : ', X_train.shape)\n",
    "print('X_valid : ', X_valid.shape)\n",
    "print('X_test : ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_train, axis=(0,1,2,3))\n",
    "std=np.std(X_train, axis=(0,1,2,3))\n",
    "\n",
    "offset= 1e-7\n",
    "X_train = (X_train-mean)/(std+offset)\n",
    "X_valid = (X_valid-mean)/(std+offset)\n",
    "X_test = (X_test-mean)/(std+offset)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "y_valid = np_utils.to_categorical(y_valid, num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True, vertical_flip=False)\n",
    "\n",
    "data_gen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 8, 8, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 8, 8, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_hidden_units=32\n",
    "weight_decay=1e-4\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "# Conv1\n",
    "model.add(Conv2D(base_hidden_units, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Conv2\n",
    "model.add(Conv2D(base_hidden_units, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Pool + Dropout\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Conv3\n",
    "model.add(Conv2D(base_hidden_units * 2, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Conv4\n",
    "model.add(Conv2D(base_hidden_units * 2, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Pool + Dropout\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Conv5\n",
    "model.add(Conv2D(base_hidden_units * 4, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Conv6\n",
    "model.add(Conv2D(base_hidden_units * 4, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Pool + Dropout\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# FC7\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\777\\AppData\\Local\\Temp\\ipykernel_1108\\3629338417.py:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(data_gen.flow(X_train, y_train, batch_size=batch_size), callbacks=[checkpointer],\\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.99403, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 20s - loss: 2.3325 - accuracy: 0.3076 - val_loss: 1.9940 - val_accuracy: 0.3130 - 20s/epoch - 56ms/step\n",
      "Epoch 2/125\n",
      "\n",
      "Epoch 2: val_loss improved from 1.99403 to 1.42576, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 18s - loss: 1.8044 - accuracy: 0.4038 - val_loss: 1.4258 - val_accuracy: 0.5030 - 18s/epoch - 50ms/step\n",
      "Epoch 3/125\n",
      "\n",
      "Epoch 3: val_loss improved from 1.42576 to 1.33138, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 1.6332 - accuracy: 0.4489 - val_loss: 1.3314 - val_accuracy: 0.5328 - 17s/epoch - 50ms/step\n",
      "Epoch 4/125\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.33138\n",
      "351/351 - 17s - loss: 1.5310 - accuracy: 0.4800 - val_loss: 1.3701 - val_accuracy: 0.5282 - 17s/epoch - 48ms/step\n",
      "Epoch 5/125\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.33138\n",
      "351/351 - 17s - loss: 1.4470 - accuracy: 0.5047 - val_loss: 1.3908 - val_accuracy: 0.5346 - 17s/epoch - 49ms/step\n",
      "Epoch 6/125\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.33138\n",
      "351/351 - 17s - loss: 1.3753 - accuracy: 0.5318 - val_loss: 1.3928 - val_accuracy: 0.5458 - 17s/epoch - 49ms/step\n",
      "Epoch 7/125\n",
      "\n",
      "Epoch 7: val_loss improved from 1.33138 to 1.30052, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 1.3109 - accuracy: 0.5516 - val_loss: 1.3005 - val_accuracy: 0.5710 - 17s/epoch - 50ms/step\n",
      "Epoch 8/125\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.30052\n",
      "351/351 - 18s - loss: 1.2548 - accuracy: 0.5727 - val_loss: 1.3657 - val_accuracy: 0.5718 - 18s/epoch - 51ms/step\n",
      "Epoch 9/125\n",
      "\n",
      "Epoch 9: val_loss improved from 1.30052 to 1.18906, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 1.2076 - accuracy: 0.5900 - val_loss: 1.1891 - val_accuracy: 0.6074 - 17s/epoch - 50ms/step\n",
      "Epoch 10/125\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.18906\n",
      "351/351 - 17s - loss: 1.1698 - accuracy: 0.6012 - val_loss: 1.2746 - val_accuracy: 0.5886 - 17s/epoch - 47ms/step\n",
      "Epoch 11/125\n",
      "\n",
      "Epoch 11: val_loss improved from 1.18906 to 1.17013, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 1.1299 - accuracy: 0.6142 - val_loss: 1.1701 - val_accuracy: 0.6150 - 17s/epoch - 48ms/step\n",
      "Epoch 12/125\n",
      "\n",
      "Epoch 12: val_loss improved from 1.17013 to 1.14187, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 1.0985 - accuracy: 0.6242 - val_loss: 1.1419 - val_accuracy: 0.6312 - 17s/epoch - 49ms/step\n",
      "Epoch 13/125\n",
      "\n",
      "Epoch 13: val_loss improved from 1.14187 to 1.10799, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 18s - loss: 1.0613 - accuracy: 0.6367 - val_loss: 1.1080 - val_accuracy: 0.6434 - 18s/epoch - 51ms/step\n",
      "Epoch 14/125\n",
      "\n",
      "Epoch 14: val_loss improved from 1.10799 to 1.07026, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 18s - loss: 1.0317 - accuracy: 0.6493 - val_loss: 1.0703 - val_accuracy: 0.6574 - 18s/epoch - 50ms/step\n",
      "Epoch 15/125\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.07026\n",
      "351/351 - 17s - loss: 1.0103 - accuracy: 0.6572 - val_loss: 1.0832 - val_accuracy: 0.6490 - 17s/epoch - 48ms/step\n",
      "Epoch 16/125\n",
      "\n",
      "Epoch 16: val_loss improved from 1.07026 to 1.03366, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.9801 - accuracy: 0.6687 - val_loss: 1.0337 - val_accuracy: 0.6726 - 17s/epoch - 49ms/step\n",
      "Epoch 17/125\n",
      "\n",
      "Epoch 17: val_loss improved from 1.03366 to 1.01741, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.9549 - accuracy: 0.6763 - val_loss: 1.0174 - val_accuracy: 0.6740 - 17s/epoch - 48ms/step\n",
      "Epoch 18/125\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.01741\n",
      "351/351 - 17s - loss: 0.9289 - accuracy: 0.6868 - val_loss: 1.0217 - val_accuracy: 0.6798 - 17s/epoch - 48ms/step\n",
      "Epoch 19/125\n",
      "\n",
      "Epoch 19: val_loss improved from 1.01741 to 0.99550, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.9080 - accuracy: 0.6948 - val_loss: 0.9955 - val_accuracy: 0.6924 - 17s/epoch - 49ms/step\n",
      "Epoch 20/125\n",
      "\n",
      "Epoch 20: val_loss improved from 0.99550 to 0.87897, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 18s - loss: 0.9042 - accuracy: 0.6956 - val_loss: 0.8790 - val_accuracy: 0.7172 - 18s/epoch - 50ms/step\n",
      "Epoch 21/125\n",
      "\n",
      "Epoch 21: val_loss improved from 0.87897 to 0.85203, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.8754 - accuracy: 0.7053 - val_loss: 0.8520 - val_accuracy: 0.7236 - 17s/epoch - 49ms/step\n",
      "Epoch 22/125\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.85203\n",
      "351/351 - 17s - loss: 0.8605 - accuracy: 0.7112 - val_loss: 0.8824 - val_accuracy: 0.7176 - 17s/epoch - 47ms/step\n",
      "Epoch 23/125\n",
      "\n",
      "Epoch 23: val_loss improved from 0.85203 to 0.82833, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.8383 - accuracy: 0.7180 - val_loss: 0.8283 - val_accuracy: 0.7352 - 17s/epoch - 48ms/step\n",
      "Epoch 24/125\n",
      "\n",
      "Epoch 24: val_loss improved from 0.82833 to 0.82277, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.8224 - accuracy: 0.7250 - val_loss: 0.8228 - val_accuracy: 0.7368 - 17s/epoch - 48ms/step\n",
      "Epoch 25/125\n",
      "\n",
      "Epoch 25: val_loss improved from 0.82277 to 0.82150, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.8074 - accuracy: 0.7280 - val_loss: 0.8215 - val_accuracy: 0.7452 - 17s/epoch - 49ms/step\n",
      "Epoch 26/125\n",
      "\n",
      "Epoch 26: val_loss improved from 0.82150 to 0.81407, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.8027 - accuracy: 0.7303 - val_loss: 0.8141 - val_accuracy: 0.7468 - 17s/epoch - 49ms/step\n",
      "Epoch 27/125\n",
      "\n",
      "Epoch 27: val_loss improved from 0.81407 to 0.71972, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.7818 - accuracy: 0.7374 - val_loss: 0.7197 - val_accuracy: 0.7752 - 17s/epoch - 49ms/step\n",
      "Epoch 28/125\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.71972\n",
      "351/351 - 17s - loss: 0.7658 - accuracy: 0.7456 - val_loss: 0.7240 - val_accuracy: 0.7706 - 17s/epoch - 48ms/step\n",
      "Epoch 29/125\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.71972\n",
      "351/351 - 17s - loss: 0.7537 - accuracy: 0.7472 - val_loss: 0.7403 - val_accuracy: 0.7616 - 17s/epoch - 49ms/step\n",
      "Epoch 30/125\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.71972\n",
      "351/351 - 17s - loss: 0.7487 - accuracy: 0.7496 - val_loss: 0.7423 - val_accuracy: 0.7614 - 17s/epoch - 48ms/step\n",
      "Epoch 31/125\n",
      "\n",
      "Epoch 31: val_loss improved from 0.71972 to 0.68184, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.7356 - accuracy: 0.7540 - val_loss: 0.6818 - val_accuracy: 0.7834 - 17s/epoch - 49ms/step\n",
      "Epoch 32/125\n",
      "\n",
      "Epoch 32: val_loss improved from 0.68184 to 0.67642, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.7208 - accuracy: 0.7600 - val_loss: 0.6764 - val_accuracy: 0.7826 - 17s/epoch - 50ms/step\n",
      "Epoch 33/125\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.67642\n",
      "351/351 - 17s - loss: 0.7141 - accuracy: 0.7609 - val_loss: 0.6983 - val_accuracy: 0.7788 - 17s/epoch - 48ms/step\n",
      "Epoch 34/125\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.67642\n",
      "351/351 - 17s - loss: 0.7001 - accuracy: 0.7696 - val_loss: 0.6941 - val_accuracy: 0.7756 - 17s/epoch - 49ms/step\n",
      "Epoch 35/125\n",
      "\n",
      "Epoch 35: val_loss improved from 0.67642 to 0.66608, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.6954 - accuracy: 0.7706 - val_loss: 0.6661 - val_accuracy: 0.7868 - 17s/epoch - 48ms/step\n",
      "Epoch 36/125\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.66608\n",
      "351/351 - 17s - loss: 0.6848 - accuracy: 0.7730 - val_loss: 0.6943 - val_accuracy: 0.7810 - 17s/epoch - 49ms/step\n",
      "Epoch 37/125\n",
      "\n",
      "Epoch 37: val_loss improved from 0.66608 to 0.66167, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 18s - loss: 0.6798 - accuracy: 0.7750 - val_loss: 0.6617 - val_accuracy: 0.7904 - 18s/epoch - 50ms/step\n",
      "Epoch 38/125\n",
      "\n",
      "Epoch 38: val_loss improved from 0.66167 to 0.64895, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.6741 - accuracy: 0.7758 - val_loss: 0.6489 - val_accuracy: 0.7966 - 17s/epoch - 50ms/step\n",
      "Epoch 39/125\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.64895\n",
      "351/351 - 17s - loss: 0.6619 - accuracy: 0.7809 - val_loss: 0.6706 - val_accuracy: 0.7908 - 17s/epoch - 49ms/step\n",
      "Epoch 40/125\n",
      "\n",
      "Epoch 40: val_loss improved from 0.64895 to 0.62313, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.6526 - accuracy: 0.7823 - val_loss: 0.6231 - val_accuracy: 0.8062 - 17s/epoch - 48ms/step\n",
      "Epoch 41/125\n",
      "\n",
      "Epoch 41: val_loss improved from 0.62313 to 0.60363, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.6426 - accuracy: 0.7863 - val_loss: 0.6036 - val_accuracy: 0.8150 - 17s/epoch - 49ms/step\n",
      "Epoch 42/125\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.60363\n",
      "351/351 - 17s - loss: 0.6428 - accuracy: 0.7888 - val_loss: 0.6195 - val_accuracy: 0.8088 - 17s/epoch - 48ms/step\n",
      "Epoch 43/125\n",
      "\n",
      "Epoch 43: val_loss improved from 0.60363 to 0.59933, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.6287 - accuracy: 0.7915 - val_loss: 0.5993 - val_accuracy: 0.8078 - 17s/epoch - 49ms/step\n",
      "Epoch 44/125\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.59933\n",
      "351/351 - 18s - loss: 0.6264 - accuracy: 0.7934 - val_loss: 0.6287 - val_accuracy: 0.8008 - 18s/epoch - 50ms/step\n",
      "Epoch 45/125\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.59933\n",
      "351/351 - 17s - loss: 0.6281 - accuracy: 0.7941 - val_loss: 0.6440 - val_accuracy: 0.7966 - 17s/epoch - 48ms/step\n",
      "Epoch 46/125\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.59933\n",
      "351/351 - 17s - loss: 0.6144 - accuracy: 0.7986 - val_loss: 0.6089 - val_accuracy: 0.8106 - 17s/epoch - 47ms/step\n",
      "Epoch 47/125\n",
      "\n",
      "Epoch 47: val_loss improved from 0.59933 to 0.57307, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.6013 - accuracy: 0.8039 - val_loss: 0.5731 - val_accuracy: 0.8198 - 17s/epoch - 48ms/step\n",
      "Epoch 48/125\n",
      "\n",
      "Epoch 48: val_loss improved from 0.57307 to 0.56311, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.6024 - accuracy: 0.8023 - val_loss: 0.5631 - val_accuracy: 0.8198 - 17s/epoch - 48ms/step\n",
      "Epoch 49/125\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.56311\n",
      "351/351 - 17s - loss: 0.5971 - accuracy: 0.8033 - val_loss: 0.5712 - val_accuracy: 0.8230 - 17s/epoch - 49ms/step\n",
      "Epoch 50/125\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.56311\n",
      "351/351 - 17s - loss: 0.5881 - accuracy: 0.8061 - val_loss: 0.5839 - val_accuracy: 0.8196 - 17s/epoch - 49ms/step\n",
      "Epoch 51/125\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.56311\n",
      "351/351 - 17s - loss: 0.5902 - accuracy: 0.8077 - val_loss: 0.5882 - val_accuracy: 0.8172 - 17s/epoch - 48ms/step\n",
      "Epoch 52/125\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.56311\n",
      "351/351 - 17s - loss: 0.5818 - accuracy: 0.8074 - val_loss: 0.5661 - val_accuracy: 0.8234 - 17s/epoch - 48ms/step\n",
      "Epoch 53/125\n",
      "\n",
      "Epoch 53: val_loss improved from 0.56311 to 0.56159, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.5756 - accuracy: 0.8118 - val_loss: 0.5616 - val_accuracy: 0.8252 - 17s/epoch - 49ms/step\n",
      "Epoch 54/125\n",
      "\n",
      "Epoch 54: val_loss improved from 0.56159 to 0.55972, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 18s - loss: 0.5657 - accuracy: 0.8147 - val_loss: 0.5597 - val_accuracy: 0.8244 - 18s/epoch - 52ms/step\n",
      "Epoch 55/125\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.55972\n",
      "351/351 - 17s - loss: 0.5645 - accuracy: 0.8138 - val_loss: 0.5640 - val_accuracy: 0.8238 - 17s/epoch - 50ms/step\n",
      "Epoch 56/125\n",
      "\n",
      "Epoch 56: val_loss improved from 0.55972 to 0.53137, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 18s - loss: 0.5544 - accuracy: 0.8187 - val_loss: 0.5314 - val_accuracy: 0.8362 - 18s/epoch - 50ms/step\n",
      "Epoch 57/125\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.53137\n",
      "351/351 - 17s - loss: 0.5549 - accuracy: 0.8175 - val_loss: 0.5684 - val_accuracy: 0.8240 - 17s/epoch - 49ms/step\n",
      "Epoch 58/125\n",
      "\n",
      "Epoch 58: val_loss improved from 0.53137 to 0.52959, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.5491 - accuracy: 0.8202 - val_loss: 0.5296 - val_accuracy: 0.8362 - 17s/epoch - 50ms/step\n",
      "Epoch 59/125\n",
      "\n",
      "Epoch 59: val_loss improved from 0.52959 to 0.52601, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.5437 - accuracy: 0.8232 - val_loss: 0.5260 - val_accuracy: 0.8368 - 17s/epoch - 48ms/step\n",
      "Epoch 60/125\n",
      "\n",
      "Epoch 60: val_loss improved from 0.52601 to 0.50736, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.5396 - accuracy: 0.8224 - val_loss: 0.5074 - val_accuracy: 0.8400 - 17s/epoch - 48ms/step\n",
      "Epoch 61/125\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.50736\n",
      "351/351 - 17s - loss: 0.5327 - accuracy: 0.8263 - val_loss: 0.5344 - val_accuracy: 0.8352 - 17s/epoch - 49ms/step\n",
      "Epoch 62/125\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.50736\n",
      "351/351 - 17s - loss: 0.5301 - accuracy: 0.8268 - val_loss: 0.5771 - val_accuracy: 0.8250 - 17s/epoch - 49ms/step\n",
      "Epoch 63/125\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.50736\n",
      "351/351 - 17s - loss: 0.5255 - accuracy: 0.8298 - val_loss: 0.5796 - val_accuracy: 0.8194 - 17s/epoch - 48ms/step\n",
      "Epoch 64/125\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.50736\n",
      "351/351 - 17s - loss: 0.5241 - accuracy: 0.8310 - val_loss: 0.5339 - val_accuracy: 0.8348 - 17s/epoch - 49ms/step\n",
      "Epoch 65/125\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.50736\n",
      "351/351 - 17s - loss: 0.5225 - accuracy: 0.8303 - val_loss: 0.5156 - val_accuracy: 0.8418 - 17s/epoch - 48ms/step\n",
      "Epoch 66/125\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.50736\n",
      "351/351 - 17s - loss: 0.5146 - accuracy: 0.8323 - val_loss: 0.5127 - val_accuracy: 0.8414 - 17s/epoch - 48ms/step\n",
      "Epoch 67/125\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.50736\n",
      "351/351 - 17s - loss: 0.5114 - accuracy: 0.8334 - val_loss: 0.5436 - val_accuracy: 0.8302 - 17s/epoch - 49ms/step\n",
      "Epoch 68/125\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.50736\n",
      "351/351 - 17s - loss: 0.5100 - accuracy: 0.8330 - val_loss: 0.5257 - val_accuracy: 0.8372 - 17s/epoch - 48ms/step\n",
      "Epoch 69/125\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.50736\n",
      "351/351 - 17s - loss: 0.5051 - accuracy: 0.8344 - val_loss: 0.5183 - val_accuracy: 0.8402 - 17s/epoch - 49ms/step\n",
      "Epoch 70/125\n",
      "\n",
      "Epoch 70: val_loss improved from 0.50736 to 0.50043, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.4967 - accuracy: 0.8380 - val_loss: 0.5004 - val_accuracy: 0.8452 - 17s/epoch - 48ms/step\n",
      "Epoch 71/125\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.50043\n",
      "351/351 - 17s - loss: 0.4956 - accuracy: 0.8380 - val_loss: 0.5392 - val_accuracy: 0.8350 - 17s/epoch - 48ms/step\n",
      "Epoch 72/125\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.50043\n",
      "351/351 - 17s - loss: 0.4931 - accuracy: 0.8397 - val_loss: 0.5364 - val_accuracy: 0.8356 - 17s/epoch - 48ms/step\n",
      "Epoch 73/125\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.50043\n",
      "351/351 - 17s - loss: 0.4918 - accuracy: 0.8393 - val_loss: 0.5405 - val_accuracy: 0.8338 - 17s/epoch - 49ms/step\n",
      "Epoch 74/125\n",
      "\n",
      "Epoch 74: val_loss improved from 0.50043 to 0.49339, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.4883 - accuracy: 0.8425 - val_loss: 0.4934 - val_accuracy: 0.8496 - 17s/epoch - 49ms/step\n",
      "Epoch 75/125\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.49339\n",
      "351/351 - 17s - loss: 0.4821 - accuracy: 0.8447 - val_loss: 0.5136 - val_accuracy: 0.8450 - 17s/epoch - 49ms/step\n",
      "Epoch 76/125\n",
      "\n",
      "Epoch 76: val_loss improved from 0.49339 to 0.48348, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.4868 - accuracy: 0.8412 - val_loss: 0.4835 - val_accuracy: 0.8486 - 17s/epoch - 48ms/step\n",
      "Epoch 77/125\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.48348\n",
      "351/351 - 17s - loss: 0.4822 - accuracy: 0.8437 - val_loss: 0.5167 - val_accuracy: 0.8432 - 17s/epoch - 48ms/step\n",
      "Epoch 78/125\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.48348\n",
      "351/351 - 17s - loss: 0.4747 - accuracy: 0.8455 - val_loss: 0.5209 - val_accuracy: 0.8418 - 17s/epoch - 48ms/step\n",
      "Epoch 79/125\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.48348\n",
      "351/351 - 17s - loss: 0.4725 - accuracy: 0.8469 - val_loss: 0.4957 - val_accuracy: 0.8478 - 17s/epoch - 49ms/step\n",
      "Epoch 80/125\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.48348\n",
      "351/351 - 18s - loss: 0.4689 - accuracy: 0.8483 - val_loss: 0.4867 - val_accuracy: 0.8528 - 18s/epoch - 50ms/step\n",
      "Epoch 81/125\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.48348\n",
      "351/351 - 17s - loss: 0.4648 - accuracy: 0.8492 - val_loss: 0.5102 - val_accuracy: 0.8442 - 17s/epoch - 48ms/step\n",
      "Epoch 82/125\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.48348\n",
      "351/351 - 17s - loss: 0.4635 - accuracy: 0.8495 - val_loss: 0.5147 - val_accuracy: 0.8462 - 17s/epoch - 47ms/step\n",
      "Epoch 83/125\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.48348\n",
      "351/351 - 17s - loss: 0.4671 - accuracy: 0.8485 - val_loss: 0.4963 - val_accuracy: 0.8490 - 17s/epoch - 48ms/step\n",
      "Epoch 84/125\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.48348\n",
      "351/351 - 17s - loss: 0.4544 - accuracy: 0.8530 - val_loss: 0.4948 - val_accuracy: 0.8496 - 17s/epoch - 48ms/step\n",
      "Epoch 85/125\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.48348\n",
      "351/351 - 17s - loss: 0.4552 - accuracy: 0.8530 - val_loss: 0.5007 - val_accuracy: 0.8484 - 17s/epoch - 49ms/step\n",
      "Epoch 86/125\n",
      "\n",
      "Epoch 86: val_loss improved from 0.48348 to 0.48307, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.4573 - accuracy: 0.8510 - val_loss: 0.4831 - val_accuracy: 0.8502 - 17s/epoch - 49ms/step\n",
      "Epoch 87/125\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.48307\n",
      "351/351 - 17s - loss: 0.4431 - accuracy: 0.8560 - val_loss: 0.5081 - val_accuracy: 0.8452 - 17s/epoch - 49ms/step\n",
      "Epoch 88/125\n",
      "\n",
      "Epoch 88: val_loss improved from 0.48307 to 0.48127, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.4417 - accuracy: 0.8564 - val_loss: 0.4813 - val_accuracy: 0.8516 - 17s/epoch - 49ms/step\n",
      "Epoch 89/125\n",
      "\n",
      "Epoch 89: val_loss improved from 0.48127 to 0.47213, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.4480 - accuracy: 0.8557 - val_loss: 0.4721 - val_accuracy: 0.8480 - 17s/epoch - 49ms/step\n",
      "Epoch 90/125\n",
      "\n",
      "Epoch 90: val_loss improved from 0.47213 to 0.46968, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.4463 - accuracy: 0.8548 - val_loss: 0.4697 - val_accuracy: 0.8554 - 17s/epoch - 48ms/step\n",
      "Epoch 91/125\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.46968\n",
      "351/351 - 17s - loss: 0.4383 - accuracy: 0.8597 - val_loss: 0.4760 - val_accuracy: 0.8544 - 17s/epoch - 49ms/step\n",
      "Epoch 92/125\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.46968\n",
      "351/351 - 17s - loss: 0.4315 - accuracy: 0.8622 - val_loss: 0.4913 - val_accuracy: 0.8506 - 17s/epoch - 50ms/step\n",
      "Epoch 93/125\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.46968\n",
      "351/351 - 17s - loss: 0.4376 - accuracy: 0.8594 - val_loss: 0.4804 - val_accuracy: 0.8546 - 17s/epoch - 48ms/step\n",
      "Epoch 94/125\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.46968\n",
      "351/351 - 17s - loss: 0.4338 - accuracy: 0.8598 - val_loss: 0.5039 - val_accuracy: 0.8466 - 17s/epoch - 48ms/step\n",
      "Epoch 95/125\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.46968\n",
      "351/351 - 17s - loss: 0.4328 - accuracy: 0.8607 - val_loss: 0.4969 - val_accuracy: 0.8498 - 17s/epoch - 48ms/step\n",
      "Epoch 96/125\n",
      "\n",
      "Epoch 96: val_loss improved from 0.46968 to 0.46665, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.4273 - accuracy: 0.8622 - val_loss: 0.4666 - val_accuracy: 0.8604 - 17s/epoch - 49ms/step\n",
      "Epoch 97/125\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.46665\n",
      "351/351 - 17s - loss: 0.4214 - accuracy: 0.8620 - val_loss: 0.4806 - val_accuracy: 0.8538 - 17s/epoch - 49ms/step\n",
      "Epoch 98/125\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.46665\n",
      "351/351 - 17s - loss: 0.4262 - accuracy: 0.8638 - val_loss: 0.4763 - val_accuracy: 0.8538 - 17s/epoch - 49ms/step\n",
      "Epoch 99/125\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.46665\n",
      "351/351 - 17s - loss: 0.4224 - accuracy: 0.8638 - val_loss: 0.4725 - val_accuracy: 0.8578 - 17s/epoch - 48ms/step\n",
      "Epoch 100/125\n",
      "\n",
      "Epoch 100: val_loss improved from 0.46665 to 0.45561, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.4190 - accuracy: 0.8631 - val_loss: 0.4556 - val_accuracy: 0.8642 - 17s/epoch - 48ms/step\n",
      "Epoch 101/125\n",
      "\n",
      "Epoch 101: val_loss improved from 0.45561 to 0.44619, saving model to mini_vggnet.125epochs.hdf5\n",
      "351/351 - 17s - loss: 0.4214 - accuracy: 0.8647 - val_loss: 0.4462 - val_accuracy: 0.8652 - 17s/epoch - 49ms/step\n",
      "Epoch 102/125\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.4181 - accuracy: 0.8655 - val_loss: 0.4657 - val_accuracy: 0.8606 - 17s/epoch - 48ms/step\n",
      "Epoch 103/125\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.4129 - accuracy: 0.8675 - val_loss: 0.4849 - val_accuracy: 0.8520 - 17s/epoch - 49ms/step\n",
      "Epoch 104/125\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.4110 - accuracy: 0.8673 - val_loss: 0.4618 - val_accuracy: 0.8616 - 17s/epoch - 49ms/step\n",
      "Epoch 105/125\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.4079 - accuracy: 0.8689 - val_loss: 0.4792 - val_accuracy: 0.8580 - 17s/epoch - 49ms/step\n",
      "Epoch 106/125\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.4081 - accuracy: 0.8675 - val_loss: 0.4569 - val_accuracy: 0.8616 - 17s/epoch - 47ms/step\n",
      "Epoch 107/125\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.4070 - accuracy: 0.8684 - val_loss: 0.4644 - val_accuracy: 0.8610 - 17s/epoch - 48ms/step\n",
      "Epoch 108/125\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.4068 - accuracy: 0.8698 - val_loss: 0.4652 - val_accuracy: 0.8594 - 17s/epoch - 49ms/step\n",
      "Epoch 109/125\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.4032 - accuracy: 0.8713 - val_loss: 0.4659 - val_accuracy: 0.8604 - 17s/epoch - 49ms/step\n",
      "Epoch 110/125\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.44619\n",
      "351/351 - 19s - loss: 0.4017 - accuracy: 0.8718 - val_loss: 0.4911 - val_accuracy: 0.8548 - 19s/epoch - 53ms/step\n",
      "Epoch 111/125\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.3959 - accuracy: 0.8719 - val_loss: 0.4756 - val_accuracy: 0.8558 - 17s/epoch - 50ms/step\n",
      "Epoch 112/125\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.3957 - accuracy: 0.8736 - val_loss: 0.4886 - val_accuracy: 0.8534 - 17s/epoch - 48ms/step\n",
      "Epoch 113/125\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.3973 - accuracy: 0.8732 - val_loss: 0.4876 - val_accuracy: 0.8562 - 17s/epoch - 48ms/step\n",
      "Epoch 114/125\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.3979 - accuracy: 0.8736 - val_loss: 0.4482 - val_accuracy: 0.8644 - 17s/epoch - 48ms/step\n",
      "Epoch 115/125\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.3933 - accuracy: 0.8736 - val_loss: 0.4680 - val_accuracy: 0.8640 - 17s/epoch - 49ms/step\n",
      "Epoch 116/125\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.44619\n",
      "351/351 - 18s - loss: 0.3897 - accuracy: 0.8756 - val_loss: 0.4514 - val_accuracy: 0.8630 - 18s/epoch - 50ms/step\n",
      "Epoch 117/125\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.3917 - accuracy: 0.8747 - val_loss: 0.4732 - val_accuracy: 0.8608 - 17s/epoch - 49ms/step\n",
      "Epoch 118/125\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.3867 - accuracy: 0.8773 - val_loss: 0.4657 - val_accuracy: 0.8626 - 17s/epoch - 49ms/step\n",
      "Epoch 119/125\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.3946 - accuracy: 0.8746 - val_loss: 0.4588 - val_accuracy: 0.8630 - 17s/epoch - 48ms/step\n",
      "Epoch 120/125\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.3851 - accuracy: 0.8771 - val_loss: 0.4535 - val_accuracy: 0.8636 - 17s/epoch - 48ms/step\n",
      "Epoch 121/125\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.3845 - accuracy: 0.8758 - val_loss: 0.4572 - val_accuracy: 0.8676 - 17s/epoch - 49ms/step\n",
      "Epoch 122/125\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.3802 - accuracy: 0.8776 - val_loss: 0.4608 - val_accuracy: 0.8642 - 17s/epoch - 49ms/step\n",
      "Epoch 123/125\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.3775 - accuracy: 0.8792 - val_loss: 0.4584 - val_accuracy: 0.8682 - 17s/epoch - 49ms/step\n",
      "Epoch 124/125\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.3780 - accuracy: 0.8795 - val_loss: 0.4707 - val_accuracy: 0.8634 - 17s/epoch - 48ms/step\n",
      "Epoch 125/125\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.44619\n",
      "351/351 - 17s - loss: 0.3751 - accuracy: 0.8812 - val_loss: 0.4552 - val_accuracy: 0.8654 - 17s/epoch - 48ms/step\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "epochs=125\n",
    "\n",
    "checkpointer= ModelCheckpoint(filepath='mini_vggnet.125epochs.hdf5', verbose=1, save_best_only=True)\n",
    "adam_optimizer = keras.optimizers.Adam(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(data_gen.flow(X_train, y_train, batch_size=batch_size), callbacks=[checkpointer],\\\n",
    "    steps_per_epoch=X_train.shape[0] // batch_size, epochs=epochs, verbose=2, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 1s 8ms/step - loss: 0.5065 - accuracy: 0.8518\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, batch_size = batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result : 0.852 loss: 0.507\n"
     ]
    }
   ],
   "source": [
    "print(\"Test result : %.3f loss: %.3f\"%(scores[1], scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='valid')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe7e35a9f2f3de21f54100d33f4f30d27a89ac45856d743fc93d9d66411222da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
